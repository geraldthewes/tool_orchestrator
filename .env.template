# ToolOrchestra Environment Configuration
# Copy this file to .env and update values as needed

# =============================================================================
# ORCHESTRATOR MODEL
# =============================================================================
# The main orchestrator LLM endpoint (vLLM/SGLang/any OpenAI-compatible)
ORCHESTRATOR_BASE_URL=http://localhost:8001/v1
ORCHESTRATOR_MODEL=nvidia/Nemotron-Orchestrator-8B

# =============================================================================
# DELEGATE LLMs (by function, not model name)
# =============================================================================

# Reasoning LLM - For complex reasoning and analysis tasks
# Configure with any large reasoning model (OpenAI-compatible endpoint)
REASONING_LLM_BASE_URL=http://localhost:30000/v1
REASONING_LLM_MODEL=openai/gpt-oss-120b

# Coding LLM - For code generation and debugging tasks
# Configure with any coding-focused model (OpenAI-compatible endpoint)
CODING_LLM_BASE_URL=http://localhost:8000/v1
CODING_LLM_MODEL=qwen3-coder

# Fast LLM - For quick reasoning tasks
# Configure with any fast model (Ollama endpoint)
FAST_LLM_URL=http://localhost:11434/api/chat
FAST_LLM_MODEL=nemotron-3-nano

# =============================================================================
# TOOLS
# =============================================================================

# SearXNG Web Search (local instance or any SearXNG endpoint)
SEARXNG_ENDPOINT=http://localhost:8080/search

# =============================================================================
# RUNTIME SETTINGS
# =============================================================================

# Maximum orchestration steps before giving up
MAX_ORCHESTRATION_STEPS=10

# Default temperature for orchestrator
ORCHESTRATOR_TEMPERATURE=0.7

# Python executor timeout (seconds)
PYTHON_EXECUTOR_TIMEOUT=30

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO
